{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981eccd5",
   "metadata": {},
   "source": [
    "# SoulScript Agent Walkthrough (LLM, Context, Memory)\n",
    "\n",
    "Runnable guide focused on the agent stack (LLM calls, context aggregation, and memory). Scheduler/tick orchestration is deliberately omitted. The seeds here are hardcoded to match the repo format so you can run this notebook anywhere in the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f980b2d",
   "metadata": {},
   "source": [
    "## Repo + env setup\n",
    "Purpose: locate the repo root, add it to `sys.path`, and load `.env` so LLM keys are available.\n",
    "\n",
    "Example input: current working directory.\n",
    "Example output: resolved `REPO_ROOT` and `sys.path` confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992011c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_root: c:\\Users\\Computia.me\\Documents\\Github\\Project-SoulScript\n",
      "sys.path contains repo_root: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "def _find_repo_root() -> Path:\n",
    "    candidates = [Path.cwd(), *Path.cwd().parents]\n",
    "    if \"__file__\" in globals():\n",
    "        here = Path(__file__).resolve()\n",
    "        candidates.append(here.parent)\n",
    "        candidates.extend(here.parents)\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"soulscript\" / \"core\" / \"config.py\").exists():\n",
    "            return candidate\n",
    "    return Path.cwd()\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "env_path = REPO_ROOT / \".env\"\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        stripped = line.strip()\n",
    "        if not stripped or stripped.startswith(\"#\") or \"=\" not in stripped:\n",
    "            continue\n",
    "        key, value = stripped.split(\"=\", 1)\n",
    "        if key and value and key not in os.environ:\n",
    "            os.environ[key] = value\n",
    "\n",
    "print(\"repo_root:\", REPO_ROOT)\n",
    "print(\"sys.path contains repo_root:\", str(REPO_ROOT) in sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b47f7",
   "metadata": {},
   "source": [
    "## Architecture \n",
    "- **Seeds → NPC containers:** authored JSON → `NPCTruth` → `NPCProfile` (immutable truth), wrapped by `NPC` for mood/self-perception.\n",
    "- **LLM clients:** `OllamaLLMClient` (local) and `OpenRouterLLMClient` (remote) share the same prompt schema and validation.\n",
    "- **Policy + context aggregation:** `apply_policy` picks allowed actions + tool outputs; `_build_llm_context` merges profile, memory, world context, and tools for the prompt.\n",
    "- **Validator + decision:** `_validated_decision` enforces action constraints and retries/falls back on junk outputs.\n",
    "- **Memory:** `ConversationMemory` stores short-term lines and long-term summaries; feeds back into context. Relationship graph is available but the scheduler loop is not used here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d2537",
   "metadata": {},
   "source": [
    "## Hardcoded seeds\n",
    "\n",
    "\n",
    "Example input: two NPC truth dicts.\n",
    "Example output: `NPCProfile` objects ready for the agent stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d1a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['npc_mara', 'npc_riven']\n"
     ]
    }
   ],
   "source": [
    "from soulscript.core.types import NPCProfile, NPCTruth, TraitVector\n",
    "\n",
    "seed_a = {\n",
    "    \"id\": \"npc_mara\",\n",
    "    \"name\": \"Mara\",\n",
    "    \"age\": 29,\n",
    "    \"race\": \"half-orc\",\n",
    "    \"sex\": \"female\",\n",
    "    \"sexual_orientation\": \"bisexual\",\n",
    "    \"backstory\": \"Hired blade looking for steady guard work and a warm seat.\",\n",
    "    \"traits\": \"Tall, scarred, soft-voiced, quick to check others are okay.\",\n",
    "    \"motivation\": \"Find steady guard work near the fire.\",\n",
    "    \"role\": \"visitor\",\n",
    "    \"trait_inputs\": {\"honesty\": 60, \"patience\": 45, \"optimism\": 10, \"charisma\": 20},\n",
    "    \"traits_truth\": {\n",
    "        \"kindness\": 55, \"bravery\": 75, \"extraversion\": -5, \"ego\": -10, \"honesty\": 60,\n",
    "        \"curiosity\": 25, \"patience\": 50, \"optimism\": 5, \"intelligence\": 50, \"charisma\": 15,\n",
    "    },\n",
    "    \"traits_self_perception\": {\n",
    "        \"kindness\": 60, \"bravery\": 80, \"extraversion\": 0, \"ego\": -5, \"honesty\": 65,\n",
    "        \"curiosity\": 20, \"patience\": 45, \"optimism\": 10, \"intelligence\": 45, \"charisma\": 20,\n",
    "    },\n",
    "    \"inventory\": [\"patched cloak\", \"armband\", \"memento ring\"],\n",
    "    \"schedule\": {\"morning\": \"market\", \"afternoon\": \"tavern_common\", \"evening\": \"tavern_common\"},\n",
    "    \"initial_relationships\": {},\n",
    "}\n",
    "seed_b = {\n",
    "    \"id\": \"npc_riven\",\n",
    "    \"name\": \"Riven\",\n",
    "    \"age\": 31,\n",
    "    \"race\": \"human\",\n",
    "    \"sex\": \"male\",\n",
    "    \"sexual_orientation\": \"heterosexual\",\n",
    "    \"backstory\": \"Courier who keeps stopping in for news and warm meals.\",\n",
    "    \"traits\": \"Lean, weathered, easy smile, always checking doorways.\",\n",
    "    \"motivation\": \"Trade gossip for meals and rest.\",\n",
    "    \"role\": \"local\",\n",
    "    \"trait_inputs\": {\"honesty\": 55, \"patience\": 30, \"optimism\": 25, \"charisma\": 35},\n",
    "    \"traits_truth\": {\n",
    "        \"kindness\": 40, \"bravery\": 55, \"extraversion\": 25, \"ego\": 5, \"honesty\": 55,\n",
    "        \"curiosity\": 45, \"patience\": 35, \"optimism\": 30, \"intelligence\": 45, \"charisma\": 35,\n",
    "    },\n",
    "    \"traits_self_perception\": {\n",
    "        \"kindness\": 45, \"bravery\": 60, \"extraversion\": 30, \"ego\": 10, \"honesty\": 50,\n",
    "        \"curiosity\": 50, \"patience\": 30, \"optimism\": 35, \"intelligence\": 40, \"charisma\": 40,\n",
    "    },\n",
    "    \"inventory\": [\"mail satchel\", \"folded maps\"],\n",
    "    \"schedule\": {\"morning\": \"tavern_common\", \"afternoon\": \"market\", \"evening\": \"tavern_common\"},\n",
    "    \"initial_relationships\": {},\n",
    "}\n",
    "\n",
    "profiles = [NPCProfile(truth=NPCTruth(**seed_a)), NPCProfile(truth=NPCTruth(**seed_b))]\n",
    "print([p.truth.npc_id for p in profiles])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7983b0",
   "metadata": {},
   "source": [
    "## LLM calls: local Ollama and OpenRouter option\n",
    "Purpose: exercise both LLM providers with the same minimal context. After this, default to OpenRouter for the rest of the notebook.\n",
    "\n",
    "Example input: shared context + allowed actions.\n",
    "Example output: `Decision` objects with action/line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b269d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouter: npc_id='npc_mara' selected_action=Action(action_type=<ActionType.SPEAK: 'speak'>, target_id='npc_riven', metadata={}) reason='Engaging positively about the stew to create a friendly atmosphere.' dialogue_line='It really does! I hope it tastes as good as it smells.' confidence=0.6\n"
     ]
    }
   ],
   "source": [
    "from soulscript.core import config\n",
    "from soulscript.core.llm import OllamaLLMClient, OpenRouterLLMClient\n",
    "from soulscript.core.types import Action, ActionType\n",
    "\n",
    "sample_profile = profiles[0]\n",
    "partner_id = profiles[1].truth.npc_id\n",
    "trait_scale = {\n",
    "    \"kindness\": \"-100=cruel, 100=kind\",\n",
    "    \"bravery\": \"-100=cowardly, 100=brave\",\n",
    "    \"extraversion\": \"-100=withdrawn, 100=gregarious\",\n",
    "    \"ego\": \"-100=selfless, 100=proud\",\n",
    "    \"honesty\": \"-100=dishonest, 100=honest\",\n",
    "    \"curiosity\": \"-100=apathetic, 100=seeking\",\n",
    "    \"patience\": \"-100=impulsive, 100=patient\",\n",
    "    \"optimism\": \"-100=cynical, 100=hopeful\",\n",
    "    \"intelligence\": \"-100=dim, 100=brilliant\",\n",
    "    \"charisma\": \"-100=off-putting, 100=magnetic\",\n",
    "}\n",
    "shared_context = {\n",
    "    \"profile\": {\n",
    "        \"name\": sample_profile.truth.name,\n",
    "        \"backstory\": sample_profile.truth.backstory,\n",
    "        \"motivation\": sample_profile.truth.motivation,\n",
    "        \"traits_summary\": sample_profile.truth.traits,\n",
    "        \"trait_scale\": trait_scale,\n",
    "    },\n",
    "    \"state\": {\n",
    "        \"mood\": 55,\n",
    "        \"traits_truth\": sample_profile.truth.traits_truth.as_dict(),\n",
    "    },\n",
    "    \"short_term\": [f\"{partner_id}: The stew smells great.\"],\n",
    "    \"recent_thread\": [f\"{partner_id}: The stew smells great.\"],\n",
    "    \"last_partner_line\": \"The stew smells great.\",\n",
    "    \"long_term\": \"\",\n",
    "    \"global_facts\": list(config.GLOBAL_KNOWLEDGE),\n",
    "    \"conversation_partner\": partner_id,\n",
    "    \"interaction_tone\": \"Quick hello in the tavern.\",\n",
    "}\n",
    "allowed_actions = [\n",
    "    Action(action_type=ActionType.SPEAK, target_id=partner_id),\n",
    "    Action(action_type=ActionType.IDLE, target_id=partner_id),\n",
    "]\n",
    "\n",
    "# orig_provider = config.LLM_PROVIDER\n",
    "# config.LLM_PROVIDER = \"ollama\"\n",
    "# local_llm = OllamaLLMClient()\n",
    "# local_decision = local_llm.select_action(sample_profile.truth.npc_id, shared_context, allowed_actions)\n",
    "config.LLM_PROVIDER = \"openrouter\"\n",
    "remote_llm = OpenRouterLLMClient()\n",
    "remote_decision = remote_llm.select_action(sample_profile.truth.npc_id, shared_context, allowed_actions)\n",
    "config.LLM_PROVIDER = orig_provider\n",
    "\n",
    "#print(\"Local/Ollama:\", local_decision)\n",
    "print(\"OpenRouter:\", remote_decision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a79c86",
   "metadata": {},
   "source": [
    "## Context aggregation (policy + prompt bundle)\n",
    "Purpose: show how `apply_policy` and `_build_llm_context` produce the LLM-ready payload.\n",
    "\n",
    "Example input: NPC profile, mood, world context for a focused pair.\n",
    "Example output: allowed actions, tool outputs, and the merged context dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2398100e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed actions: ['speak', 'idle']\n",
      "Tool outputs: {'inventory': ['patched cloak', 'armband', 'memento ring'], 'schedule': {'morning': 'market', 'afternoon': 'tavern_common', 'evening': 'tavern_common'}}\n",
      "Context keys: ['allowed_npcs', 'conversation_partner', 'defer_effects', 'focus_target', 'global_facts', 'interaction_tone', 'inventory', 'last_partner_line', 'long_term', 'profile', 'recent_thread', 'schedule', 'short_term', 'state']\n",
      "Short term: []\n",
      "Global facts: ['You are in a cozy fantasy tavern.', 'Half the people here are locals and half are visitors.', 'Keep dialogue short and friendly.']\n"
     ]
    }
   ],
   "source": [
    "from soulscript.core.runtime import apply_policy, _build_llm_context, ConversationMemory, RelationshipGraph\n",
    "\n",
    "memory = ConversationMemory()\n",
    "relationships = RelationshipGraph()\n",
    "relationships.bootstrap([p.truth.npc_id for p in profiles], seeds={})\n",
    "\n",
    "world_context = {\n",
    "    \"focus_target\": partner_id,\n",
    "    \"defer_effects\": True,\n",
    "    \"allowed_npcs\": [sample_profile.truth.npc_id, partner_id],\n",
    "}\n",
    "allowed_actions_ctx, tool_outputs = apply_policy(sample_profile, \"speak\", world_context)\n",
    "llm_context = _build_llm_context(\n",
    "    sample_profile,\n",
    "    npc_mood=55,\n",
    "    conversation_memory=memory,\n",
    "    context=world_context,\n",
    "    tool_outputs=tool_outputs,\n",
    "    relationships=relationships,\n",
    ")\n",
    "print(\"Allowed actions:\", [a.action_type.value for a in allowed_actions_ctx])\n",
    "print(\"Tool outputs:\", tool_outputs)\n",
    "print(\"Context keys:\", sorted(llm_context.keys()))\n",
    "print(\"Short term:\", llm_context.get(\"short_term\"))\n",
    "print(\"Global facts:\", llm_context.get(\"global_facts\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdaad9",
   "metadata": {},
   "source": [
    "## Memory section (short-term + summary)\n",
    "Purpose: demonstrate `ConversationMemory.record` and `context_bundle` that feeds context aggregation.\n",
    "\n",
    "Example input: a few dialogue lines between Mara and Riven.\n",
    "Example output: ordered short-term lines and auto-generated long-term summary when the trigger is hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbdb0b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short term: ['npc_riven: Long ride, but worth the company.', 'npc_mara: You look tired from travel.', 'npc_riven: Warm food helps the road.', 'npc_mara: Quiet night by the fire.']\n",
      "Long term summary: I caught up with npc_riven. They mentioned 'Warm food helps the road.' I replied 'Quiet night by the fire.'\n",
      "Global facts: ['You are in a cozy fantasy tavern.', 'Half the people here are locals and half are visitors.', 'Keep dialogue short and friendly.']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "memory = ConversationMemory()\n",
    "now = datetime.utcnow()\n",
    "memory.record(\"npc_mara\", \"npc_riven\", \"npc_mara\", \"Quiet night by the fire.\", now)\n",
    "memory.record(\"npc_mara\", \"npc_riven\", \"npc_riven\", \"Warm food helps the road.\", now)\n",
    "memory.record(\"npc_mara\", \"npc_riven\", \"npc_mara\", \"You look tired from travel.\", now)\n",
    "memory.record(\"npc_mara\", \"npc_riven\", \"npc_riven\", \"Long ride, but worth the company.\", now)\n",
    "\n",
    "bundle = memory.context_bundle(\"npc_mara\", \"npc_riven\", existing_summary=None)\n",
    "print(\"Short term:\", bundle[\"short_term\"])\n",
    "print(\"Long term summary:\", bundle[\"long_term\"])\n",
    "print(\"Global facts:\", bundle[\"global_facts\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffec3e",
   "metadata": {},
   "source": [
    "## Relationship perception \n",
    "Purpose: show the perception edge after the conversation snippets; no scheduler needed.\n",
    "\n",
    "Example input: adjust relation directly.\n",
    "Example output: trust/affinity and perceived traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1937949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trust': 2, 'affinity': 2, 'summary': \"I caught up with npc_riven. They mentioned 'Warm food helps the road.' I replied 'Quiet night by the fire.'\", 'traits': {'kindness': 1, 'bravery': 0, 'extraversion': 0, 'ego': 0, 'honesty': 0, 'curiosity': 0, 'patience': 0, 'optimism': 0, 'intelligence': 0, 'charisma': 0}}\n"
     ]
    }
   ],
   "source": [
    "edge = relationships.adjust_relation(\n",
    "    source_id=\"npc_mara\",\n",
    "    target_id=\"npc_riven\",\n",
    "    trust_delta=2,\n",
    "    affinity_delta=2,\n",
    "    trait_deltas={\"kindness\": 1},\n",
    "    summary=bundle[\"long_term\"],\n",
    "    timestamp=datetime.utcnow(),\n",
    ")\n",
    "print({\"trust\": edge.trust, \"affinity\": edge.affinity, \"summary\": edge.summary, \"traits\": edge.traits.as_dict()})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soulscript",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
